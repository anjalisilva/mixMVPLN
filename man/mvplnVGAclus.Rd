% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mvplnVGAclus.R
\name{mvplnVGAclus}
\alias{mvplnVGAclus}
\title{Clustering Using mixtures of MVPLN via variational Gaussian approximations}
\usage{
mvplnVGAclus(
  dataset,
  membership = "none",
  gmin,
  gmax,
  initMethod = "kmeans",
  nInitIterations = 0,
  normalize = "Yes"
)
}
\arguments{
\item{dataset}{A list of length nUnits, containing Y_j matrices.
A matrix Y_j has size r x p, and the dataset will have 'j' such
matrices with j = 1,...,n. If a Y_j has all zeros, such Y_j will
be removed prior to cluster analysis.}

\item{membership}{A numeric vector of size length(dataset) containing
the cluster membership of each Y_j matrix. If not available, leave
as "none".}

\item{gmin}{A positive integer specifying the minimum number of
components to be considered in the clustering run.}

\item{gmax}{A positive integer, >gmin, specifying the maximum number of
components to be considered in the clustering run.}

\item{initMethod}{A method for initialization. Current options are
"none", "kmeans", "random", "medoids", "clara", or "fanny".
Default is "none".}

\item{nInitIterations}{A positive integer or zero, specifying the number
of initialization runs to be considered. Default is 0.}

\item{normalize}{A string with options "Yes" or "No" specifying
if normalization should be performed. Currently, normalization
factors are calculated using TMM method of edgeR package.
Default is "Yes".}

\item{nChains}{A positive integer specifying the number of Markov chains.
Default is 3, the recommended minimum number.}

\item{nIterations}{A positive integer specifying the number of iterations
for each MCMC chain (including warmup). The value should be greater
than 40. The upper limit will depend on size of dataset.}
}
\value{
Returns an S3 object of class mvplnParallel with results.
\itemize{
  \item dataset - The input dataset on which clustering is performed.
  \item nUnits - Number of units in the input dataset.
  \item nVariables - Number of variables in the input dataset.
  \item nOccassions - Number of occassions in the input dataset.
  \item normFactors - A vector of normalization factors used for
     input dataset.
  \item gmin - Minimum number of components considered in the
     clustering run.
  \item gmax - Maximum number of components considered in the
     clustering run.
  \item initalizationMethod - Method used for initialization.
  \item allResults - A list with all results.
  \item loglikelihood - A vector with value of final log-likelihoods
     for each cluster size.
  \item nParameters - A vector with number of parameters for each
     cluster size.
  \item trueLabels - The vector of true labels, if provided by user.
  \item ICL_all - A list with all ICL model selection results.
  \item BIC_all - A list with all BIC model selection results.
  \item AIC_all - A list with all AIC model selection results.
  \item AIC3_all - A list with all AIC3 model selection results.
  \item totalTime - Total time used for clustering and model selection.
}
}
\description{
Performs clustering using mixtures of matrix variate Poisson-log normal
(MVPLN) via variational Gaussian approximations. Model selection can
be done using AIC, AIC3, BIC and ICL.
}
\examples{
\dontrun{
# Example 1
# Generating simulated matrix variate count data
set.seed(1234)
trueG <- 2 # number of total G
truer <- 2 # number of total occasions
truep <- 3 # number of total responses
trueN <- 1000 # number of total units
truePiG <- c(0.6, 0.4) # mixing proportions for G=2

# Mu is a r x p matrix
trueM1 <- matrix(rep(6.2, (truer * truep)),
                 ncol = truep,
                 nrow = truer,
                 byrow = TRUE)

trueM2 <- matrix(rep(1.5, (truer * truep)),
                 ncol = truep,
                 nrow = truer,
                 byrow = TRUE)

trueMall <- rbind(trueM1, trueM2)

# Phi is a r x r matrix
# Loading needed packages for generating data
# install.packages("clusterGeneration")
# library("clusterGeneration")

set.seed(1)
truePhi1 <- matrix(rep(0, truer * truer), truer, truer)
diag(truePhi1) <- diag(clusterGeneration::genPositiveDefMat(
                       "unifcorrmat",
                        dim = truer,
                        rangeVar = c(1, 1.7))$Sigma)
truePhi1[1, 1] <- 1 # for identifiability issuess
truePhi2 <- matrix(rep(0,truer * truer), truer, truer)
diag(truePhi2) <- diag(clusterGeneration::genPositiveDefMat(
                       "unifcorrmat",
                        dim = truer,
                        rangeVar = c(0.7, 0.7))$Sigma)
truePhi2[1, 1] <- 1 # for identifiability issues
truePhiall <- rbind(truePhi1, truePhi2)


# Omega is a p x p matrix
set.seed(1)
trueOmega1 <- matrix(rep(0, truep * truep), truep, truep)
diag(trueOmega1) <- diag(clusterGeneration::genPositiveDefMat(
                         "unifcorrmat",
                          dim = truep,
                          rangeVar = c(1, 1.7))$Sigma)
trueOmega2 <- matrix(rep(0, truep * truep), truep, truep)
diag(trueOmega2) <- diag(clusterGeneration::genPositiveDefMat(
                         "unifcorrmat",
                          dim = truep,
                         mrangeVar = c(0.6, 0.9))$Sigma)
trueOmegaAll <- rbind(trueOmega1, trueOmega2)

# Generated simulated data
sampleData <- mixMVPLN::mvplnDataGenerator(
                         nOccasions = truer,
                         nResponses = truep,
                         nUnits = trueN,
                         mixingProportions = truePiG,
                         matrixMean = trueMall,
                         phi = truePhiall,
                         omega = trueOmegaAll)

# Clustering simulated matrix variate count data
clusteringResults <- mixMVPLN::mvplnVGAclus(
                      dataset = sampleData$dataset,
                      membership = sampleData$truemembership,
                      gmin = 1,
                      gmax = 3,
                      initMethod = "kmeans",
                      nInitIterations = 2,
                      normalize = "Yes")

# Example 2
trueG <- 1 # 1 cluster
truer <- 2 # variety
truep <- 3 # growth stages
trueN <- 1000 # genes
truePiG <- c(1) # mixing proportions for G = 1

# Mu is a r x p matrix
trueM1 <- matrix(c(6, 5.5, 6, 6, 5.5, 6),
                 ncol = truep,
                 nrow = truer,
                 byrow = TRUE)
trueMall <- rbind(trueM1)
# Phi is a r x r matrix
set.seed(1)
truePhi1 <- clusterGeneration::genPositiveDefMat(
                              "unifcorrmat",
                              dim = truer,
                              rangeVar = c(0.7, 1.7))$Sigma
truePhi1[1, 1] <- 1 # for identifiability issues
truePhiall <- rbind(truePhi1)

# Omega is a p x p matrix
set.seed(1)
trueOmega1 <- genPositiveDefMat(
                   "unifcorrmat",
                    dim = truep,
                    rangeVar = c(1, 1.7))$Sigma
trueOmegaAll <- rbind(trueOmega1)

# Generated simulated data
set.seed(1)
sampleData2 <- mixMVPLN::mvplnDataGenerator(
                         nOccasions = truer,
                         nResponses = truep,
                         nUnits = trueN,
                         mixingProportions = truePiG,
                         matrixMean = trueMall,
                         phi = truePhiall,
                         omega = trueOmegaAll)

# Clustering simulated matrix variate count data
clusteringResults <- mixMVPLN::mvplnVGAclus(
                      dataset = sampleData2$dataset,
                      membership = sampleData2$truemembership,
                      gmin = 1,
                      gmax = 2,
                      initMethod = "kmeans",
                      nInitIterations = 2,
                      normalize = "Yes")

}

}
\references{
Aitchison, J. and C. H. Ho (1989). The multivariate Poisson-log normal distribution.
\emph{Biometrika} 76.

Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In \emph{Second International Symposium on Information Theory}, New York, NY,
USA, pp. 267–281. Springer Verlag.

Arlot, S., Brault, V., Baudry, J., Maugis, C., and Michel, B. (2016).
capushe: CAlibrating Penalities Using Slope HEuristics. R package version 1.1.1.

Biernacki, C., G. Celeux, and G. Govaert (2000). Assessing a mixture model for
clustering with the integrated classification likelihood. \emph{IEEE Transactions
on Pattern Analysis and Machine Intelligence} 22.

Bozdogan, H. (1994). Mixture-model cluster analysis using model selection criteria
and a new informational measure of complexity. In \emph{Proceedings of the First US/Japan
Conference on the Frontiers of Statistical Modeling: An Informational Approach:
Volume 2 Multivariate Statistical Modeling}, pp. 69–113. Dordrecht: Springer Netherlands.

Robinson, M.D., and Oshlack, A. (2010). A scaling normalization method for differential
expression analysis of RNA-seq data. \emph{Genome Biology} 11, R25.

Schwarz, G. (1978). Estimating the dimension of a model. \emph{The Annals of Statistics}
6.

Silva, A. et al. (2019). A multivariate Poisson-log normal mixture model
for clustering transcriptome sequencing data. \emph{BMC Bioinformatics} 20.
\href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2916-0}{Link}

Silva, A. et al. (2018). Finite Mixtures of Matrix Variate Poisson-Log Normal Distributions
for Three-Way Count Data. \href{https://arxiv.org/abs/1807.08380}{arXiv preprint arXiv:1807.08380}.
}
\author{
{Anjali Silva, \email{anjali@alumni.uoguelph.ca}, Sanjeena Dang,
         \email{sanjeenadang@cunet.carleton.ca}. }
}
